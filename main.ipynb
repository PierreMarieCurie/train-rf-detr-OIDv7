{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8342e7fb",
   "metadata": {},
   "source": [
    "Version de Python: au moins 3.9 pour rfdetr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa64eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from downloader import download_all_images\n",
    "import tempfile\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FOLDER = 'csv_folder'\n",
    "CSV_FILENAME = {\n",
    "    \"train\": \"oidv6-train-annotations-bbox.csv\",\n",
    "    \"valid\": \"validation-annotations-bbox.csv\",\n",
    "    \"test\": \"test-annotations-bbox.csv\",\n",
    "    \"class\": \"oidv7-class-descriptions-boxable.csv\"\n",
    "}\n",
    "TARGET_CLASSES = [\"wheelchair\", \"bicycle\"]\n",
    "DATA_TYPE = ['train', 'valid', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82d156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, download_dir):\n",
    "    \"\"\"\n",
    "    Download a file from the given URL into the specified directory,\n",
    "    displaying a progress bar during the download.\n",
    "\n",
    "    The filename is extracted from the URL's path.\n",
    "    Skips download if the file already exists.\n",
    "    \"\"\"\n",
    "    # Ensure the target directory exists\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    # Extract the filename from the URL\n",
    "    filename = os.path.basename(urlparse(url).path)\n",
    "    if not filename:\n",
    "        raise ValueError(f\"Could not extract filename from URL: {url}\")\n",
    "    \n",
    "    file_path = os.path.join(download_dir, filename)\n",
    "\n",
    "    # Skip downloading if file already exists\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"[SKIP] {file_path} already exists.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        print(f\"[DOWNLOAD] {file_path} from {url}\")\n",
    "\n",
    "        # Open the URL for reading the file content\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            # Attempt to get the total size for progress tracking\n",
    "            total_size = int(response.getheader('Content-Length', 0))\n",
    "            chunk_size = 1024  # Download in 1KB chunks\n",
    "\n",
    "            # Open the target file for writing and show a progress bar\n",
    "            with open(file_path, 'wb') as out_file, tqdm(\n",
    "                total=total_size,\n",
    "                unit='B',\n",
    "                unit_scale=True,\n",
    "                desc=filename,\n",
    "                leave=False\n",
    "            ) as pbar:\n",
    "                # Read and write the file chunk by chunk\n",
    "                while True:\n",
    "                    chunk = response.read(chunk_size)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    out_file.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "\n",
    "        print(f\"[DONE] {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Raise a clear error if download fails\n",
    "        raise RuntimeError(f\"Failed to download {filename} from {url}: {e}\")\n",
    "\n",
    "def download_from_manifest(manifest_path, download_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Download multiple files listed in a manifest file.\n",
    "\n",
    "    Each line of the manifest should contain a URL (one per line).\n",
    "    Lines starting with '#' are ignored (treated as comments).\n",
    "    Files are saved into the specified download directory.\n",
    "    \"\"\"\n",
    "    # Check that the manifest file exists\n",
    "    if not os.path.isfile(manifest_path):\n",
    "        raise FileNotFoundError(f\"Manifest file not found: {manifest_path}\")\n",
    "\n",
    "    # Read and clean all non-comment lines from the manifest\n",
    "    with open(manifest_path, \"r\") as f:\n",
    "        urls = [\n",
    "            line.strip() for line in f\n",
    "            if line.strip() and not line.strip().startswith(\"#\")\n",
    "        ]\n",
    "\n",
    "    print(f\"[INFO] Found {len(urls)} files to download.\\n\")\n",
    "\n",
    "    # Download each file listed in the manifest\n",
    "    for url in urls:\n",
    "        download_file(url, download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172bc9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 4 files to download.\n",
      "\n",
      "[SKIP] csv_folder/oidv6-train-annotations-bbox.csv already exists.\n",
      "[SKIP] csv_folder/validation-annotations-bbox.csv already exists.\n",
      "[SKIP] csv_folder/test-annotations-bbox.csv already exists.\n",
      "[SKIP] csv_folder/oidv7-class-descriptions-boxable.csv already exists.\n"
     ]
    }
   ],
   "source": [
    "download_from_manifest(\"csv_manifest.txt\", download_dir=CSV_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "433e6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csv_folder/oidv7-class-descriptions-boxable.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_description_csv = os.path.join(CSV_FOLDER, CSV_FILENAME['class'])\n",
    "class_description_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f266cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_names_from_display_names(csv_path, display_names):\n",
    "    \"\"\"\n",
    "    Given a list of display names and a CSV file with 'LabelName' and 'DisplayName' columns,\n",
    "    return a list of matching LabelNames. Returns None for names not found.\n",
    "\n",
    "    Matching is case-insensitive and ignores spaces/underscores.\n",
    "    \"\"\"\n",
    "    if len(display_names) != len(set(display_names)):\n",
    "        raise ValueError(\"List display_names must be unique.\")\n",
    "    \n",
    "    def normalize(name):\n",
    "        return name.strip().lower().replace(\" \", \"\").replace(\"_\", \"\")\n",
    "\n",
    "    # Build lookup map from normalized display names to original inputs\n",
    "    target_names = {normalize(name): name for name in display_names}\n",
    "    results = {name: None for name in display_names}\n",
    "\n",
    "    with open(csv_path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            norm_display = normalize(row[\"DisplayName\"])\n",
    "            if norm_display in target_names:\n",
    "                original = target_names[norm_display]\n",
    "                results[original] = row[\"LabelName\"]\n",
    "\n",
    "    # Preserve input order in output\n",
    "    return [results[name] for name in display_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbb7fd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] ./downloader.py already exists.\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_SCRIPT_URL = \"https://raw.githubusercontent.com/openimages/dataset/master/downloader.py\"\n",
    "download_file(DOWNLOAD_SCRIPT_URL, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0238711f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/m/0qmmr', '/m/0199g']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categories\n",
    "labels = get_label_names_from_display_names(class_description_csv, TARGET_CLASSES) \n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "552b151e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'name': 'wheelchair', 'supercategory': 'none'},\n",
       " {'id': 1, 'name': 'bicycle', 'supercategory': 'none'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [\n",
    "    {'id':i, \"name\": TARGET_CLASSES[i], \"supercategory\": \"none\"}\n",
    "    for i in range(len(labels))\n",
    "]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e65433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_OIDv7_data(csv_path, labels):\n",
    "    \"\"\"\n",
    "    Returns --- TO DOOOOOOOOOOOOOOOOOOOOO dire que c'est minimal, juste ce qu'il faut\n",
    "\n",
    "    Parameters:\n",
    "    - csv_path: str, path to the CSV file.\n",
    "    - target_labels: list of str, LabelNames to filter for.\n",
    "\n",
    "    Returns:\n",
    "    - List of unique ImageIDs (str).\n",
    "    \"\"\"\n",
    "\n",
    "    annotations = []\n",
    "    image_IDs = {} # use of a dict because 'in' is faster on a dict than a list\n",
    "    xyxyn = []\n",
    "    \n",
    "    # Count lines for progress bar total\n",
    "    with open(csv_path, 'r') as f:\n",
    "        total_lines = sum(1 for _ in f) - 1  # minus 1 for the header\n",
    "\n",
    "    with open(csv_path, newline='') as csvfile:\n",
    "        \n",
    "        reader = csv.DictReader(csvfile)\n",
    "        filename = os.path.basename(urlparse(csv_path).path)\n",
    "        \n",
    "        for row in tqdm(reader, total=total_lines, desc=f\"Processing {filename}\"):\n",
    "            \n",
    "            if row['LabelName'] in labels:                    \n",
    "                imageID = row['ImageID']\n",
    "                \n",
    "                if imageID not in image_IDs:\n",
    "                    image_IDs[imageID] = len(image_IDs)\n",
    "                                    \n",
    "                annotations.append(\n",
    "                    {\n",
    "                        \"image_id\": image_IDs[imageID],\n",
    "                        \"category_id\": labels.index(row['LabelName'])\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                xyxyn.append([float(row['XMin']), float(row['YMin']), float(row['XMax']), float(row['YMax'])])\n",
    "\n",
    "    return list(image_IDs), annotations, xyxyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d06ff0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_dimensions(folder_path):\n",
    "    image_info = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".jpg\"):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            with Image.open(filepath) as img:\n",
    "                width, height = img.size\n",
    "                key = os.path.splitext(filename)[0]  # Remove .jpg\n",
    "                image_info[key] = {\n",
    "                    \"width\": width,\n",
    "                    \"height\": height\n",
    "                }\n",
    "\n",
    "    return image_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33edc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyxyn_to_xywh(xyxyn, image_width, image_height):\n",
    "    x_min, y_min, x_max, y_max = xyxyn\n",
    "\n",
    "    x = x_min * image_width\n",
    "    y = y_min * image_height\n",
    "    width = (x_max - x_min) * image_width\n",
    "    height = (y_max - y_min) * image_height\n",
    "\n",
    "    return [x, y, width, height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c14b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing oidv6-train-annotations-bbox.csv: 100%|██████████| 14610229/14610229 [01:05<00:00, 222086.57it/s]\n",
      "Writing to file: 100%|██████████| 18491/18491 [00:00<00:00, 295909.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total in read_image_list_file = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 0it [00:00, ?it/s]\n",
      "Processing validation-annotations-bbox.csv: 100%|██████████| 303980/303980 [00:00<00:00, 324867.70it/s]\n",
      "Writing to file: 100%|██████████| 296/296 [00:00<00:00, 165051.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total in read_image_list_file = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 0it [00:00, ?it/s]\n",
      "Processing test-annotations-bbox.csv: 100%|██████████| 937327/937327 [00:02<00:00, 320277.39it/s]\n",
      "Writing to file: 100%|██████████| 851/851 [00:00<00:00, 255373.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total in read_image_list_file = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for data_type in DATA_TYPE:\n",
    "\n",
    "    annotation_csv = os.path.join(CSV_FOLDER, CSV_FILENAME[data_type])\n",
    "    \n",
    "    image_IDs, annotations, xyxyn = extract_OIDv7_data(annotation_csv, labels)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(mode='w+', suffix='.txt') as temp_file:\n",
    "        \n",
    "        for item in tqdm(image_IDs, desc=\"Writing to file\"):\n",
    "            file_path = f\"./dataset/{data_type}/{item}\" + \".jpg\"\n",
    "            if not os.path.exists(file_path):\n",
    "                temp_file.write(f\"{file_path}\\n\")\n",
    "        temp_file.flush()\n",
    "        \n",
    "        download_folder = f'./dataset/{data_type}'\n",
    "\n",
    "        args = {\n",
    "        'download_folder': download_folder,\n",
    "        'image_list': temp_file.name,\n",
    "        'num_processes': 5\n",
    "        }\n",
    "        download_all_images(args)\n",
    "        \n",
    "    dimensions_dict = get_image_dimensions(download_folder)\n",
    "    \n",
    "    images = [{\n",
    "        \"id\":i,\n",
    "        \"file_name\":image+'.jpg',\n",
    "        \"height\":dimensions_dict[image][\"height\"],\n",
    "        \"width\":dimensions_dict[image][\"width\"]}\n",
    "    for i, image in enumerate(image_IDs)\n",
    "    ]\n",
    "\n",
    "    annotations = [{**annotation,\n",
    "        \"bbox\":xyxyn_to_xywh(xyxyn[i],\n",
    "                            images[annotations[i]['image_id']]['width'],\n",
    "                            images[annotations[i]['image_id']]['height']),\n",
    "        \"id\":i,\n",
    "        \"area\": images[annotations[i]['image_id']]['width']*images[annotations[i]['image_id']]['height']\n",
    "        } for i, annotation in enumerate(annotations)\n",
    "    ]\n",
    "    \n",
    "    data = {\n",
    "        \"categories\": categories,\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations \n",
    "    }\n",
    "\n",
    "    with open(os.path.join(download_folder, \"_annotations.coco.json\"), \"w\") as f:\n",
    "        json.dump(data, f, indent=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ec4057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n"
     ]
    }
   ],
   "source": [
    "from rfdetr import RFDETRBase\n",
    "\n",
    "model = RFDETRBase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f434d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using batch_size=2, grad_accum_steps=8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def auto_adjust_batch_params(target_total_batch=16):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No GPU available. Using CPU.\")\n",
    "        return 1, target_total_batch  # batch_size=1, accumulate more steps\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    props = torch.cuda.get_device_properties(device)\n",
    "    total_vram_gb = props.total_memory / (1024**3)\n",
    "\n",
    "    # Example logic (adjust as needed):\n",
    "    if total_vram_gb >= 40:  # A100, etc.\n",
    "        return target_total_batch, 1\n",
    "    elif total_vram_gb >= 16:  # e.g. RTX 3080, V100\n",
    "        return 8, target_total_batch // 8\n",
    "    elif total_vram_gb >= 8:  # e.g. T4\n",
    "        return 4, target_total_batch // 4\n",
    "    else:\n",
    "        return 2, target_total_batch // 2\n",
    "\n",
    "# Example usage\n",
    "batch_size, grad_accum_steps = auto_adjust_batch_params()\n",
    "print(f\"Using batch_size={batch_size}, grad_accum_steps={grad_accum_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_classes mismatch: model has 90 classes, but your dataset has 2 classes\n",
      "reinitializing your detection head with 2 classes.\n",
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to initialize TensorBoard. Logging is turned off for this session.  Run 'pip install tensorboard' to enable logging.\n",
      "Not using distributed mode\n",
      "git:\n",
      "  sha: N/A, status: clean, branch: N/A\n",
      "\n",
      "Namespace(num_classes=2, grad_accum_steps=1500, amp=True, lr=0.0001, lr_encoder=0.00015, batch_size=1, weight_decay=0.0001, epochs=1, lr_drop=100, clip_max_norm=0.1, lr_vit_layer_decay=0.8, lr_component_decay=0.7, do_benchmark=False, dropout=0, drop_path=0.0, drop_mode='standard', drop_schedule='constant', cutoff_epoch=0, pretrained_encoder=None, pretrain_weights='rf-detr-base.pth', pretrain_exclude_keys=None, pretrain_keys_modify_to_load=None, pretrained_distiller=None, encoder='dinov2_windowed_small', vit_encoder_num_layers=12, window_block_indexes=None, position_embedding='sine', out_feature_indexes=[2, 5, 8, 11], freeze_encoder=False, layer_norm=True, rms_norm=False, backbone_lora=False, force_no_pretrain=False, dec_layers=3, dim_feedforward=2048, hidden_dim=256, sa_nheads=8, ca_nheads=16, num_queries=300, group_detr=13, two_stage=True, projector_scale=['P4'], lite_refpoint_refine=True, num_select=300, dec_n_points=2, decoder_norm='LN', bbox_reparam=True, freeze_batch_norm=False, set_cost_class=2, set_cost_bbox=5, set_cost_giou=2, cls_loss_coef=1.0, bbox_loss_coef=5, giou_loss_coef=2, focal_alpha=0.25, aux_loss=True, sum_group_losses=False, use_varifocal_loss=False, use_position_supervised_loss=False, ia_bce_loss=True, dataset_file='roboflow', coco_path=None, dataset_dir='./dataset', square_resize_div_64=True, output_dir='results', dont_save_weights=False, checkpoint_interval=10, seed=42, resume='', start_epoch=0, eval=False, use_ema=True, ema_decay=0.993, ema_tau=100, num_workers=2, device='cuda', world_size=1, dist_url='env://', sync_bn=True, fp16_eval=False, encoder_only=False, backbone_only=False, resolution=560, use_cls_token=False, multi_scale=True, expanded_scales=True, warmup_epochs=0, lr_scheduler='step', lr_min_factor=0.0, early_stopping=False, early_stopping_patience=10, early_stopping_min_delta=0.001, early_stopping_use_ema=False, gradient_checkpointing=False, tensorboard=True, wandb=False, project=None, run=None, class_names=[], distributed=False)\n",
      "number of params: 31854308\n",
      "[392, 448, 504, 560, 616, 672, 728, 784]\n",
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "[392, 448, 504, 560, 616, 672, 728, 784]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Get benchmark\n",
      "Start training\n",
      "Grad accum steps:  1500\n",
      "Total batch size:  1500\n",
      "LENGTH OF DATA LOADER: 12\n"
     ]
    }
   ],
   "source": [
    "dataset = \"./dataset\"\n",
    "model.train(dataset_dir=dataset,\n",
    "            epochs=1,\n",
    "            batch_size=1,\n",
    "            grad_accum_steps=1500,\n",
    "            lr=1e-4,\n",
    "            output_dir=\"results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train-rfdetr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
